{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a88ce2a9",
   "metadata": {},
   "source": [
    "# 层和块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8162be8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T02:55:00.900648Z",
     "start_time": "2022-08-09T02:55:00.881333Z"
    }
   },
   "source": [
    "之前⾸次介绍神经⽹络时，我们关注的是具有单⼀输出的线性模型。在这⾥，整个模型只有⼀个输出。<br>\n",
    "注意，单个神经⽹络\n",
    "1. 接受⼀些输⼊；\n",
    "2. ⽣成相应的标量输出；\n",
    "3. 具有⼀组相关 参数（parameters），更新这些参数可以优化某⽬标函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d7ee5d",
   "metadata": {},
   "source": [
    "当考虑具有多个输出的⽹络时，我们利⽤⽮量化算法来描述整层神经元。<br>\n",
    "像单个神经元⼀样，层\n",
    "1. 接受⼀组输⼊\n",
    "2. ⽣成相应的输出\n",
    "3. 由⼀组可调整参数描述。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93740d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T02:56:45.459355Z",
     "start_time": "2022-08-09T02:56:45.440120Z"
    }
   },
   "source": [
    "为了实现更复杂的⽹络，我们引⼊了神经⽹络块的概念。块（block）可以描述单个层、由多个层组成的组件或整个模型本⾝。使⽤块进⾏抽象的⼀个好处是可以将⼀些块组合成更⼤的组件，这⼀过程通常是递归的，"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8d7a9e",
   "metadata": {},
   "source": [
    "从编程的⻆度来看，块由类（class）表⽰。它的任何⼦类都必须定义⼀个将其输⼊转换为输出的前向传播函数，并且必须存储任何必需的参数。注意，有些块不需要任何参数。最后，为了计算梯度，块必须具有反向传播函数。在定义我们⾃⼰的块时，由于⾃动微分提供了⼀些后端实现，我们只需要考虑前向传播函数和必需的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c0859",
   "metadata": {},
   "source": [
    "在构造自定义块之前，我们先回顾一下多层感知机的代码。下面的代码生成一个网络，其中包含一个具有256个单元和ReLU激活函数的全连接隐藏层，然后是一个具有10个隐藏单元且不带激活函数的全连接输出层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9083ea91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:01:41.178309Z",
     "start_time": "2022-08-09T03:01:41.112173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0245, -0.0111, -0.0928, -0.0953, -0.0050,  0.0019, -0.1171, -0.1416,\n",
       "          0.0784,  0.0440],\n",
       "        [ 0.0434, -0.0726, -0.1085, -0.0335,  0.0189, -0.0921, -0.0794, -0.1732,\n",
       "         -0.0648, -0.0184]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = nn.Sequential(nn.Linear(20, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9adf0a",
   "metadata": {},
   "source": [
    "nn.Sequential定义了一种特殊的Module，即在Pytorch中表示一个块的类，它维护了一个有Module组成的有序列表。注意，两个全连接层都是Linear类的实例，Linear类本身就算Module的子类。<br>\n",
    "在调用模型时直接使用的是net(X)获得模型的输出，这实际上是运用了魔法函数`__call__(X)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02edfe12",
   "metadata": {},
   "source": [
    "## 自定义块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4698c7e7",
   "metadata": {},
   "source": [
    "想要直观地了解块是如何工作的，最简单的方法就是自己实现一个。在实现我们自定义块之前，我们简单总结一下每个块必须提供的基本功能：\n",
    "1. 将输入数据作为其前向传播函数的参数。\n",
    "2. 通过前向传播函数来生成输出。\n",
    "3. 计算其输出关于输入的梯度，可通过其反向传播函数进行访问。\n",
    "4. 存储和访问当前传播计算所需的参数。\n",
    "5. 根据需要初始化模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aa397ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:12:34.388110Z",
     "start_time": "2022-08-09T03:12:34.368395Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # 用模型参数声明层。这里，我们声明两个全连接的层\n",
    "    def __init__(self):\n",
    "        # 调用MLP的父类Module的构造函数来执行必要的初始化。\n",
    "        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)  # 隐藏层\n",
    "        self.out = nn.Linear(256, 10)  # 输出层\n",
    "        \n",
    "    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出\n",
    "    def forward(self, X):\n",
    "        # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b478e8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:12:34.730470Z",
     "start_time": "2022-08-09T03:12:34.719384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1098,  0.1047,  0.0625, -0.1535,  0.0845,  0.2014, -0.2848, -0.0389,\n",
       "         -0.2126,  0.2409],\n",
       "        [ 0.0870,  0.0876,  0.1605, -0.0286,  0.1187,  0.0536, -0.1739,  0.0941,\n",
       "         -0.0759,  0.1876]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa70c4b5",
   "metadata": {},
   "source": [
    "块的一个主要优点是它的多功能性。我们可以子类化块以创建层（如全连接层的类）、整个模型（如上面的MLP类）或具有重点复杂度的各种组件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3797074e",
   "metadata": {},
   "source": [
    "## 顺序块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2516f666",
   "metadata": {},
   "source": [
    "现在我们可以更仔细地看看Sequential类是如何工作的，回想一下Sequential的设计是为了把其他模块串起来。为了构建我们自己的简化的MySequential，我们只需要定义两个关键函数：\n",
    "1. 一种将块逐个追加到列表中的函数。\n",
    "2. 一种前向传播函数，用于将输入按追加块的顺序传递给块组成的“链条”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b386704b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:19:46.490631Z",
     "start_time": "2022-08-09T03:19:46.480565Z"
    }
   },
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员\n",
    "            # 变量_modules中。module的类型是OrderedDict\n",
    "            self._modules[str(idx)] = module\n",
    "            \n",
    "    def forward(self, X):\n",
    "        # OrderdDict保证了按照成员添加的顺序遍历它们\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585f5ba8",
   "metadata": {},
   "source": [
    "`__init__`函数将每个模块逐个添加到有序字典_modules中。你可能会好奇为什么每个Module都有一个_modules属性？以及为什么我们使用它而不是自己定义一个Python列表？简而言之，_modules的主要优点是：在模块的参数初始化过程中，系统知道在_modules字典中查找需要初始化参数的子块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70f88b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:22:40.888151Z",
     "start_time": "2022-08-09T03:22:40.875896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0161,  0.1370, -0.1066, -0.1052, -0.0573,  0.0281,  0.1026,  0.0446,\n",
       "          0.1310,  0.0329],\n",
       "        [-0.0654,  0.1250,  0.1760, -0.0270, -0.1305,  0.1387,  0.0318,  0.0599,\n",
       "          0.1033,  0.0471]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e146fe82",
   "metadata": {},
   "source": [
    "## 在前向传播函数中执行代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81428398",
   "metadata": {},
   "source": [
    "Sequential类使模型构造变得简单，允许我们组合新的架构，⽽不必定义⾃⼰的类。然⽽，并不是所有的架构都是简单的顺序架构。当需要更强的灵活性时，我们需要定义⾃⼰的块。例如，我们可能希望在前向传播函数中执⾏Python的控制流。此外，我们可能希望执⾏任意的数学运算，⽽不是简单地依赖预定义的神经⽹络层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8ebc9ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:30:25.909243Z",
     "start_time": "2022-08-09T03:30:25.890159Z"
    }
   },
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 不计算梯度的随机权重参数。因此其在训练期间保持不变\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        # 使用创建的常量参数以及relu和mm函数\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        # 复用全连接层。这相当于两个全连接层共享参数\n",
    "        X = self.linear(X)\n",
    "        # 控制流\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2102cf",
   "metadata": {},
   "source": [
    "在返回输出之前，模型做了⼀些不寻常的事情：它运⾏了⼀个while循环，在L 1 范数⼤于1的条件下，将输出向量除以2，直到它满⾜条件为⽌。最后，模型返回了X中所有项的和。注意，此操作可能不会常⽤于在任何实际任务中，只是向你展⽰如何将任意代码集成到神经⽹络计算的流程中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c8a39b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:31:25.788698Z",
     "start_time": "2022-08-09T03:31:25.767055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0529, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee605a",
   "metadata": {},
   "source": [
    "我们还可以混合搭配各种组合块的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "375d1621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:34:05.754099Z",
     "start_time": "2022-08-09T03:34:05.735806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0705, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20, 64),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(64, 32),\n",
    "                                 nn.ReLU())\n",
    "        self.linear = nn.Linear(32, 16)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7dae0d",
   "metadata": {},
   "source": [
    "## 效率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7570af",
   "metadata": {},
   "source": [
    "你可能会开始担⼼操作效率的问题。毕竟，我们在⼀个⾼性能的深度学习库中进⾏了⼤量的字典查找、代码执⾏和许多其他的Python代码。Python的问题全局解释器锁是众所周知的。在深度学习环境中，我们担⼼速度极快的GPU可能要等到CPU运⾏Python代码后才能运⾏另⼀个作业。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b09b2e",
   "metadata": {},
   "source": [
    "# 参数管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87608b08",
   "metadata": {},
   "source": [
    "在选择了架构并设置了超参数后，我们就进⼊了训练阶段。此时，我们的⽬标是找到使损失函数最⼩化的模型参数值。经过训练后，我们将需要使⽤这些参数来做出未来的预测。此外，有时我们希望提取参数，以便在其他环境中复⽤它们，将模型保存下来，以便它可以在其他软件中执⾏，或者为了获得科学的理解⽽进⾏检查。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ecc044",
   "metadata": {},
   "source": [
    "之前的介绍中，我们只依靠深度学习框架来完成训练的⼯作，⽽忽略了操作参数的具体细节。本节，我们将\n",
    "介绍以下内容：\n",
    "- 访问参数，⽤于调试、诊断和可视化。\n",
    "- 参数初始化。\n",
    "- 在不同模型组件间共享参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26af951",
   "metadata": {},
   "source": [
    "## 参数访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d98df29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:38:02.594331Z",
     "start_time": "2022-08-09T03:38:02.584263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2628],\n",
       "        [-0.4082]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee2b64",
   "metadata": {},
   "source": [
    "我们从已有模型中访问参数。当**通过Sequential类**定义模型时，我们可以通过索引来访问模型的任意层。这就像模型是⼀个列表⼀样，每层的参数都在其属性中。如下所⽰，我们可以检查第⼆个全连接层的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f1c35cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:38:42.028531Z",
     "start_time": "2022-08-09T03:38:42.015380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[-0.1541, -0.2901,  0.0169, -0.2310, -0.1171,  0.2987, -0.2756,  0.3078]])), ('bias', tensor([-0.1445]))])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3485d",
   "metadata": {},
   "source": [
    "输出的结果告诉我们⼀些重要的事情：⾸先，这个全连接层包含两个参数，分别是该层的权重和偏置。两者都存储为单精度浮点数（float32）。注意，参数名称允许唯⼀标识每个参数，即使在包含数百个层的⽹络中也是如此。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a0e299",
   "metadata": {},
   "source": [
    "### 目标参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f46394",
   "metadata": {},
   "source": [
    "注意，每个参数都表⽰为参数类的⼀个实例。要对参数执⾏任何操作，⾸先我们需要访问底层的数值。有⼏种⽅法可以做到这⼀点。有些⽐较简单，⽽另⼀些则⽐较通⽤。下⾯的代码从第⼆个全连接层（即第三个神经⽹络层）提取偏置，提取后返回的是⼀个参数类实例，并进⼀步访问该参数的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b022889b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:40:23.290305Z",
     "start_time": "2022-08-09T03:40:23.280338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.1445], requires_grad=True)\n",
      "tensor([-0.1445])\n"
     ]
    }
   ],
   "source": [
    "print(type(net[2].bias))\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc266f7d",
   "metadata": {},
   "source": [
    "参数是复合的对象，包含值、梯度和额外信息。这就是我们需要显式参数值的原因。除了值之外，我们还可以访问每个参数的梯度。在上⾯这个⽹络中，由于我们还没有调⽤反向传播，所以参数的梯度处于初始状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b643df2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:41:09.040672Z",
     "start_time": "2022-08-09T03:41:09.030828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.grad == None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e735d",
   "metadata": {},
   "source": [
    "### 一次访问所有参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5fb33",
   "metadata": {},
   "source": [
    "当我们需要对所有参数执⾏操作时，逐个访问它们可能会很⿇烦。当我们处理更复杂的块（例如，嵌套块）时，情况可能会变得特别复杂，因为我们需要递归整个树来提取每个⼦块的参数。下⾯，我们将通过演⽰来⽐较访问第⼀个全连接层的参数和访问所有层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48561f64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:44:08.286896Z",
     "start_time": "2022-08-09T03:44:08.280466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n"
     ]
    }
   ],
   "source": [
    "# 访问第一个全连接层的参数\n",
    "print(*[(name, param.shape) for name, param in net[0].named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "483fd144",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:44:26.386972Z",
     "start_time": "2022-08-09T03:44:26.375936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "# 访问所有层\n",
    "print(*[(name, param.shape) for name, param in net.named_parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a328b6",
   "metadata": {},
   "source": [
    "这为我们提供了另⼀种访问⽹络参数的⽅式，如下所⽰。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f2151d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:45:18.163516Z",
     "start_time": "2022-08-09T03:45:18.156705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1541, -0.2901,  0.0169, -0.2310, -0.1171,  0.2987, -0.2756,  0.3078]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.weight'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87224008",
   "metadata": {},
   "source": [
    "### 从嵌套块收集参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef74b26",
   "metadata": {},
   "source": [
    "让我们看看，如果我们将多个块相互嵌套，参数命名约定是如何⼯作的。我们⾸先定义⼀个⽣成块的函数（可以说是“块⼯⼚”），然后将这些块组合到更⼤的块中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3dd89f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:47:48.073959Z",
     "start_time": "2022-08-09T03:47:48.048352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2735],\n",
       "        [-0.2735]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4, 8),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(8, 4),\n",
    "                         nn.ReLU())\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        # 在这里嵌套\n",
    "        net.add_module(f'block{i}', block1())\n",
    "    return net\n",
    "\n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
    "rgnet(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8602f54",
   "metadata": {},
   "source": [
    "设计了⽹络后，我们看看它是如何⼯作的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adc84cb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:48:04.066821Z",
     "start_time": "2022-08-09T03:48:04.054804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rgnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cb7d9f",
   "metadata": {},
   "source": [
    "因为层是分层嵌套的，所以我们也可以像通过嵌套列表索引⼀样访问它们。下⾯，我们访问第⼀个主要的块中、第⼆个⼦块的第⼀层的偏置项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "597bd0af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:49:15.322324Z",
     "start_time": "2022-08-09T03:49:15.313279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1550, -0.0942, -0.2024, -0.2669,  0.0101,  0.3473, -0.3262, -0.0965])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[0][1][0].bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d37229e",
   "metadata": {},
   "source": [
    "## 参数初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7294d",
   "metadata": {},
   "source": [
    "知道了如何访问参数后，现在我们看看如何正确地初始化参数。我们在 4.8节中讨论了良好初始化的必要性。深度学习框架提供默认随机初始化，也允许我们创建⾃定义初始化方法，满⾜我们通过其他规则实现初始化权重。<br>\n",
    "\n",
    "默认情况下，PyTorch会根据⼀个范围均匀地初始化权重和偏置矩阵，这个范围是根据输⼊和输出维度计算出的。PyTorch的nn.init模块提供了多种预置初始化⽅法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe03ff69",
   "metadata": {},
   "source": [
    "### 内置初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af7e19",
   "metadata": {},
   "source": [
    "让我们首先调⽤内置的初始化器。<br>\n",
    "下⾯的代码将所有权重参数**初始化为标准差为0.01的⾼斯随机变量**，且将偏置参数设置为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e94c2ecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:54:17.360850Z",
     "start_time": "2022-08-09T03:54:17.341781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0167,  0.0012, -0.0071,  0.0068]), tensor(0.))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_normal)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efc8926",
   "metadata": {},
   "source": [
    "将所有参数**初始化为给定的常数**，⽐如初始化为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1cb12f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:55:52.001922Z",
     "start_time": "2022-08-09T03:55:51.975999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1.]), tensor(0.))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_constant(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_constant)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce21f666",
   "metadata": {},
   "source": [
    "还可以**对某些块应⽤不同的初始化方法**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589631cf",
   "metadata": {},
   "source": [
    "例如，下⾯我们使⽤Xavier初始化⽅法初始化第⼀个神经⽹络层，然后将第三个神经⽹络层初始化为常量值42。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0cc2b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:59:14.739378Z",
     "start_time": "2022-08-09T03:59:14.719323Z"
    }
   },
   "outputs": [],
   "source": [
    "def xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab5a5a0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:59:14.912066Z",
     "start_time": "2022-08-09T03:59:14.895579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5670, -0.0233,  0.1025, -0.4254])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "net[0].apply(xavier)\n",
    "net[2].apply(init_42)\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cd5728",
   "metadata": {},
   "source": [
    "### 自定义初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f73d8",
   "metadata": {},
   "source": [
    "有时，深度学习框架没有提供我们需要的初始化⽅法。在下⾯的例⼦中，我们使⽤以下的分布为任意权重参数$w$定义初始化⽅法：\n",
    "$$\n",
    "w \\sim \\begin{cases}U(5,10) & \\text { 可能性 } \\frac{1}{4} \\\\ 0 & \\text { 可能性 } \\frac{1}{2} \\\\ U(-10,-5) & \\text { 可能性 } \\frac{1}{4}\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f0786c",
   "metadata": {},
   "source": [
    "同样，我们实现了一个my_init函数来应用到net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30aba4c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T04:03:50.646181Z",
     "start_time": "2022-08-09T04:03:50.625597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  6.1604, -0.0000, -0.0000],\n",
       "        [-0.0000, -6.2209,  0.0000, -6.2103]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\"Init\", *[(name, param.shape) for name, param in m.named_parameters()][0])\n",
    "        nn.init.uniform_(m.weight, -10, 10)\n",
    "        m.weight.data *= m.weight.data.abs() >= 5\n",
    "        \n",
    "net.apply(my_init)\n",
    "net[0].weight[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4a730",
   "metadata": {},
   "source": [
    "注意，我们始终可以直接设置参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "331077e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T04:04:12.002072Z",
     "start_time": "2022-08-09T04:04:11.989679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.0000,  7.1604,  1.0000,  1.0000])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data[:] += 1\n",
    "net[0].weight.data[0, 0] = 42\n",
    "net[0].weight.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d408a483",
   "metadata": {},
   "source": [
    "## 参数绑定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13182ec8",
   "metadata": {},
   "source": [
    "有时我们希望在多个层间共享参数：我们可以定义⼀个稠密层，然后使⽤它的参数来设置另⼀个层的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b4dc8a82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T05:41:46.533842Z",
     "start_time": "2022-08-09T05:41:46.505477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "tensor([True, True, True, True, True, True, True, True])\n",
      "net[4]结果： tensor(100.)\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# 我们需要给共享层⼀个名称，以便可以引⽤它的参数\n",
    "shared = nn.Linear(8, 8)\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    nn.Linear(8, 1))\n",
    "print(net)\n",
    "net(X)\n",
    "# 检查参数是否相同\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "net[2].weight.data[0, 0] = 100\n",
    "print('net[4]结果：', net[4].weight.data[0, 0])\n",
    "# 确保它们实际上是同⼀个对象，⽽不只是有相同的值\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5c5c81",
   "metadata": {},
   "source": [
    "这个例⼦表明第三个和第五个神经⽹络层的参数是绑定的。它们不仅值相等，⽽且由相同的张量表⽰。因此，如果我们改变其中⼀个参数，另⼀个参数也会改变。你可能会思考：当参数绑定时，梯度会发⽣什么情况？答案是由于模型参数包含梯度，因此在反向传播期间第⼆个隐藏层（即第三个神经⽹络层）和第三个隐藏层（即第五个神经⽹络层）的梯度会加在⼀起。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3884864",
   "metadata": {},
   "source": [
    "# 延后初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea69a4a",
   "metadata": {},
   "source": [
    "到目前为止，我们忽略了建立网络时需要做的以下这些事情：\n",
    "- 我们定义了网络架构，但没有指定输入维度\n",
    "- 我们添加层时没有指定前一层的输出维度\n",
    "- 我们在初始化参数时，甚至没有足够的信息来确定模型应该包含多少参数\n",
    "\n",
    "你可能会对我们的代码能运行感到惊讶。毕竟，深度学习框架无法判断网络的输入维度是什么。这里的诀窍是框架的延后初始化，即直到数据第一次通过模型传递时，框架才会动态地推断出每个层的大小。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8548e6f1",
   "metadata": {},
   "source": [
    "## 实例化网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d1071f",
   "metadata": {},
   "source": [
    "nn.LazyLinear：延后初始化，全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d921d54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:02:52.515803Z",
     "start_time": "2022-08-09T07:02:52.508636Z"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.LazyLinear(256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(256, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "357e40a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:02:52.919860Z",
     "start_time": "2022-08-09T07:02:52.908855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): LazyLinear(in_features=0, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "df92155f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:03:00.375158Z",
     "start_time": "2022-08-09T07:03:00.358045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Uninitialized parameter"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "537c1f85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:03:03.326585Z",
     "start_time": "2022-08-09T07:03:03.303329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2092, -0.2179, -0.0044,  0.1780, -0.2131,  0.1658,  0.3004, -0.0157,\n",
       "         -0.1154, -0.3769],\n",
       "        [ 0.3296, -0.0757,  0.0329,  0.0812, -0.1362,  0.2927,  0.0773,  0.0638,\n",
       "         -0.0448, -0.2469]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a1888b55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:03:06.766936Z",
     "start_time": "2022-08-09T07:03:06.758875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1225, -0.1422,  0.3074,  0.3573],\n",
       "        [-0.2188,  0.0541,  0.0414,  0.0416],\n",
       "        [-0.4397, -0.2238, -0.4481, -0.1612],\n",
       "        ...,\n",
       "        [ 0.1303,  0.1513,  0.0017, -0.3045],\n",
       "        [-0.4023,  0.0995, -0.3202,  0.1096],\n",
       "        [ 0.2366,  0.3432,  0.1951,  0.2831]], requires_grad=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight  # 经过使用后会自动进行初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dbf940",
   "metadata": {},
   "source": [
    "# 自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e76017",
   "metadata": {},
   "source": [
    "深度学习成功背后的⼀个因素是神经⽹络的灵活性：我们可以⽤创造性的⽅式组合不同的层，从⽽设计出适⽤于各种任务的架构。例如，研究⼈员发明了专⻔⽤于处理图像、⽂本、序列数据和执⾏动态规划的层。未来，你会遇到或要⾃⼰发明⼀个现在在深度学习框架中还不存在的层。在这些情况下，你必须构建⾃定义层。在本节中，我们将向你展⽰如何构建。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ddd1d",
   "metadata": {},
   "source": [
    "## 不带参数的层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35f525",
   "metadata": {},
   "source": [
    "⾸先，我们构造⼀个没有任何参数的⾃定义层。如果你还记得我们对块的介绍，这应该看起来很眼熟。下⾯的CenteredLayer类要从其输⼊中减去均值。要构建它，我们只需继承基础层类并实现前向传播功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "374a078f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:05:50.724412Z",
     "start_time": "2022-08-09T07:05:50.710460Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aec35fb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:06:31.727952Z",
     "start_time": "2022-08-09T07:06:31.718547Z"
    }
   },
   "outputs": [],
   "source": [
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "72449edc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:06:55.585318Z",
     "start_time": "2022-08-09T07:06:55.549883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77374ad1",
   "metadata": {},
   "source": [
    "我们可以将层作为组件合并到更复杂的模型中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f577bc5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:08:14.312956Z",
     "start_time": "2022-08-09T07:08:14.302988Z"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e05db0",
   "metadata": {},
   "source": [
    "作为额外的健全性检查，我们可以在向该网络发送随机数据后，检查均值是否为0。由于我们处理的是浮点数，因为存储精度的原因，我们仍然可能会看到一个非常小的非零数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7da2404d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:10:30.046377Z",
     "start_time": "2022-08-09T07:10:30.032396Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-9.3132e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513dc785",
   "metadata": {},
   "source": [
    "## 带参数的层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f899ede",
   "metadata": {},
   "source": [
    "上我们知道了如何定义简单的层，下⾯我们继续定义具有参数的层，这些参数可以通过训练进⾏调整。我们可以使⽤内置函数来创建参数，这些函数提供⼀些基本的管理功能。⽐如管理访问、初始化、共享、保存和加载模型参数。这样做的好处之⼀是：我们不需要为每个⾃定义层编写⾃定义的序列化程序。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15c3e02",
   "metadata": {},
   "source": [
    "现在，让我们实现⾃定义版本的全连接层。回想⼀下，该层需要两个参数，⼀个⽤于表⽰权重，另⼀个⽤于表⽰偏置项。在此实现中，我们使⽤修正线性单元作为激活函数。该层需要输⼊参数：in_units和units，分别表⽰输⼊数和输出数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "07389b62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:15:09.861101Z",
     "start_time": "2022-08-09T07:15:09.852167Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3c48b378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:15:28.125255Z",
     "start_time": "2022-08-09T07:15:28.103085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.0367,  0.7462,  2.7232],\n",
       "        [ 0.1762,  2.0692, -0.8030],\n",
       "        [ 2.1293, -0.1297,  0.3912],\n",
       "        [-0.4883, -0.2507, -0.5120],\n",
       "        [-0.5646,  0.6213,  1.0068]], requires_grad=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6da64a",
   "metadata": {},
   "source": [
    "我们可以使用自定义层直接执行前向传播计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1978e90f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:16:13.857061Z",
     "start_time": "2022-08-09T07:16:13.838149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.9341, 2.1127],\n",
       "        [0.0000, 1.4290, 0.2516]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd43618c",
   "metadata": {},
   "source": [
    "我们还可以使用自定义层构建模型，就像使用内置的全连接层一样使用自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1a7247fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:17:18.655209Z",
     "start_time": "2022-08-09T07:17:18.629950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7789],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c17d4",
   "metadata": {},
   "source": [
    "# 读写文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed41edf",
   "metadata": {},
   "source": [
    "## 对于单个张量，我们可以直接调用load和save函数分别读写它们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c42d2019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:18:21.316203Z",
     "start_time": "2022-08-09T07:18:21.302156Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1fd8346d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:18:39.634160Z",
     "start_time": "2022-08-09T07:18:39.599625Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c8447",
   "metadata": {},
   "source": [
    "我们现在可以将存储在文件中的数据读回内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "57e3a168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:19:24.707120Z",
     "start_time": "2022-08-09T07:19:24.685516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f7ef2d",
   "metadata": {},
   "source": [
    "我们可以存储一个张量列表，然后把它们读回内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c6df248b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:20:24.250327Z",
     "start_time": "2022-08-09T07:20:24.230141Z"
    }
   },
   "outputs": [],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y], 'x-files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0cca8353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:20:58.869153Z",
     "start_time": "2022-08-09T07:20:58.856127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2, y2 = torch.load('x-files')\n",
    "x2, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8b6331",
   "metadata": {},
   "source": [
    "我们甚至可以写入或读取从字符串映射到张量的字典。当我们要读取或写入模型中的所有权重时，这很方便"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e729ba18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:22:41.490704Z",
     "start_time": "2022-08-09T07:22:41.479674Z"
    }
   },
   "outputs": [],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bc1d7a36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:22:42.098686Z",
     "start_time": "2022-08-09T07:22:42.086527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74049f2a",
   "metadata": {},
   "source": [
    "## 加载和保存模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5612c77a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:24:25.296312Z",
     "start_time": "2022-08-09T07:24:25.288197Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4a123c76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:24:49.158695Z",
     "start_time": "2022-08-09T07:24:49.151570Z"
    }
   },
   "outputs": [],
   "source": [
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bae2d6cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:25:17.342882Z",
     "start_time": "2022-08-09T07:25:17.334840Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1032b202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:26:04.118571Z",
     "start_time": "2022-08-09T07:26:04.102402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型参数\n",
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215e7c4",
   "metadata": {},
   "source": [
    "由于两个模型参数相同，所以得到的预测值应该一样，可以验证一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dc26afb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:26:25.601287Z",
     "start_time": "2022-08-09T07:26:25.583699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa9b12",
   "metadata": {},
   "source": [
    "发现预测结果确实全部都一样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca75706",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a9fd6bda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:27:18.658784Z",
     "start_time": "2022-08-09T07:27:18.303770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug  9 15:27:18 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 472.19       Driver Version: 472.19       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   42C    P8    N/A /  N/A |    365MiB /  2048MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1544    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      2132    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      6704    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      6844    C+G   ...d\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A     12076    C+G   ...m Files\\SDKDNS\\SDKDNS.exe    N/A      |\n",
      "|    0   N/A  N/A     16400    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     21108    C+G   ...kyb3d8bbwe\\HxAccounts.exe    N/A      |\n",
      "|    0   N/A  N/A     27024    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     28520    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     31328    C+G   ...tracted\\WechatBrowser.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# 查看显卡信息\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d998df",
   "metadata": {},
   "source": [
    "在PyTorch中，每个数组都有一个设备（device），我们通常将其称为上下文（context）。默认情况下，所有变量和相关的计算都分配给CPU。有时上下文可能是GPU。当我们跨多个服务器部署作业时，事情会变得更加棘手。通过智能地将数组分配给上下文，我们可以最大限度地减少在设备之间传输数据的时间。例如，当在带有GPU的服务器上训练神经网络时，我们通常希望模型的参数在GPU上。\n",
    "\n",
    "要运行此部分中的程序，至少需要俩个GPU。注意，对于大多数桌面计算机来说，这可能是奢侈的，但在云中很容易获得。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c9e77d36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:37:09.612838Z",
     "start_time": "2022-08-09T07:37:09.592711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看GPU是否可用\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "704dfb03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:36:49.738596Z",
     "start_time": "2022-08-09T07:36:49.655562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看可用GPU数量\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fae4af6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:38:32.714290Z",
     "start_time": "2022-08-09T07:38:32.703289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539dcb4",
   "metadata": {},
   "source": [
    "我们可以查询张量所在的设备，默认情况下，张量存储在cpu中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3d6ab61c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:39:36.508872Z",
     "start_time": "2022-08-09T07:39:36.493574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d75cf",
   "metadata": {},
   "source": [
    "需要注意的是，⽆论何时我们要对多个项进⾏操作，它们都必须在同⼀个设备上。例如，如果我们对两个张量求和，我们需要确保两个张量都位于同⼀个设备上，否则框架将不知道在哪⾥存储结果，甚⾄不知道在哪⾥执⾏计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c8504b0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:40:54.050424Z",
     "start_time": "2022-08-09T07:40:54.038372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在GPU上创建tensor\n",
    "X = torch.ones(2, 3, device='cuda')\n",
    "X.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c9e4e46d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:42:21.385378Z",
     "start_time": "2022-08-09T07:42:21.367198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转移前： cpu\n",
      "转移后： cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 将cpu中的tensor复制到GPU中\n",
    "# 方法一\n",
    "print('转移前：', x.device)\n",
    "z = x.to('cuda')\n",
    "print('转移后：', z.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "958a392d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:43:08.987395Z",
     "start_time": "2022-08-09T07:43:08.981415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转移前： cpu\n",
      "转移后： cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 将cpu中的tensor复制到GPU中\n",
    "# 方法二\n",
    "print('转移前：', x.device)\n",
    "z = x.cuda()\n",
    "print('转移后：', z.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e62df0",
   "metadata": {},
   "source": [
    "此方法也同样使用，当存在多张GPU时，如何在不同的GPU中进行数据的交互。<br>\n",
    "例如：将GPU0中的tensor转移到GPU1中。<br>\n",
    "Z = X.cuda(1)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9ce9a280",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:53:37.512361Z",
     "start_time": "2022-08-09T07:53:37.504250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "65527a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:53:49.146266Z",
     "start_time": "2022-08-09T07:53:49.134171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = X[0]\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77453b16",
   "metadata": {},
   "source": [
    "不同设备之间tensor是无法进行计算的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1eaeb20a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:54:19.269947Z",
     "start_time": "2022-08-09T07:54:19.231749Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18704\\1702998212.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mxx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "x + xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ccfdb",
   "metadata": {},
   "source": [
    "要使用模型进行数据的计算，也必须将模型放入GPU中，同时保证Tensor也必须在GPU中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f1bfbc07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:57:34.645715Z",
     "start_time": "2022-08-09T07:57:34.637743Z"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(3, 1))  # 模型默认也在cpu中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1a7e681c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:57:41.835297Z",
     "start_time": "2022-08-09T07:57:41.824126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0507], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x*1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "15f462b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:58:11.887290Z",
     "start_time": "2022-08-09T07:58:11.856356Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensor for argument #3 'mat2' is on CPU, but expected it to be on GPU (while checking arguments for addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18704\\2159940700.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\users\\python\\anaconda3.8\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\python\\anaconda3.8\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\python\\anaconda3.8\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\python\\anaconda3.8\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\python\\anaconda3.8\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensor for argument #3 'mat2' is on CPU, but expected it to be on GPU (while checking arguments for addmm)"
     ]
    }
   ],
   "source": [
    "net(xx*1.0)  # cpu中的模型无法计算GPU中的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6eb1af2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:58:37.914633Z",
     "start_time": "2022-08-09T07:58:37.871937Z"
    }
   },
   "outputs": [],
   "source": [
    "net1 = net.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "aae03268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T07:58:56.070903Z",
     "start_time": "2022-08-09T07:58:56.064414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3924], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1(xx)  # 将模型转移到GPU中后即可开始计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daddf29",
   "metadata": {},
   "source": [
    "总之，只要所有的数据和参数都在同⼀个设备上，我们就可以有效地学习模型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
